{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22q_V3maqRfv"
   },
   "source": [
    "# Tutorial 3: Làm việc với dữ liệu\n",
    "\n",
    "> \"Học Máy (Machine Learning) là một lĩnh vực nghiên cứu và xây dựng các giải thuật có khả năng học tự động từ dữ liệu để giải quyết các vấn đề cụ thể\". Từ đó có thể thấy, dữ liệu (data) đóng một vai trò cực kì quan trọng và là yếu tố đầu tiên cần có khi thực hiện một ứng dụng Machine Learning.\n",
    "\n",
    "*Trong bài thực hành ngay hôm nay, chúng ta sẽ cùng tìm hiểu một số khái niệm và kĩ thuật căn bản khi làm việc với các loại dữ liệu.*\n",
    "\n",
    "\n",
    "### Mục tiểu buổi học\n",
    "- Tìm hiểu các kiểu dữ liệu cơ bản trong Machine Learning\n",
    "- Làm việc với dữ liệu bảng, hình ảnh và văn bản trên Python\n",
    "- Giới thiệu một số phương pháp lưu trữ dữ liệu \n",
    "\n",
    "### Nội dung \n",
    "1 - Dữ liệu có cấu trúc\n",
    "\n",
    "2 - Dữ liệu không có cấu trúc\n",
    "- Dữ liệu hình ảnh\n",
    "- Dữ liệu văn bản\n",
    "\n",
    "3 - Lưu trữ dữ liệu (Đọc thêm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lb26a5IavPpX"
   },
   "source": [
    "## 0.1 Kết nối và lấy dữ liệu trong Google Drive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ST0WznCS46ls"
   },
   "source": [
    "Để kết nối với Google Drive, có thể dùng lệnh \n",
    "```\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "```\n",
    "Hoặc chọn vào biểu tượng `File` góc phía bên trái chọn `Mount Drive` khi đó Google Colab sẽ tự tạo kết nối tới Google Drive.\n",
    "\n",
    "![alt text](https://imgur.com/ElUvFGW.png)\n",
    "<!-- [link text](https://imgur.com/ElUvFGW.png) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23281,
     "status": "ok",
     "timestamp": 1590629711872,
     "user": {
      "displayName": "Thanh Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjrbxsDKbd9eeRTjbbqhjQcsjNVlL5ZTnzwvYV_zg=s64",
      "userId": "07489558485061570174"
     },
     "user_tz": -420
    },
    "id": "ZkMg2ITLw9qJ",
    "outputId": "bfe37fa2-b5ec-4014-c58d-7f9d7c9771d1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3003,
     "status": "ok",
     "timestamp": 1590629715270,
     "user": {
      "displayName": "Thanh Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjrbxsDKbd9eeRTjbbqhjQcsjNVlL5ZTnzwvYV_zg=s64",
      "userId": "07489558485061570174"
     },
     "user_tz": -420
    },
    "id": "YQdruKNqvPe7",
    "outputId": "4409e055-e87e-4a9a-eef5-5da01f675916"
   },
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUDD1YudqRfz"
   },
   "source": [
    "Trong Machine Learning, dữ liệu được chia thành 2 nhóm chính, là **dữ liệu có cấu trúc** (Structured Data) và **dữ liệu không có cấu trúc** (Unstructured Data).\n",
    "## 1. Dữ liệu có cấu trúc\n",
    "- Dữ liệu thường biểu diễn ở dạng bảng\n",
    "- Mỗi hàng biểu diễn một **điểm dữ liệu (instance)**\n",
    "- Các cột là các **đặc trưng (features)** và **nhãn (label)** của dữ liệu đó\n",
    "- Một cách thường dùng để lưu trữ dữ liệu có cấu trúc là lưu trữ ở dạng file **.csv** <sup>(1)</sup>\n",
    "\n",
    "Ví dụ: Iris Dataset\n",
    "\n",
    "<img src = \"https://imgur.com/SyhcVvY.jpg\" width=\"500px\"/>\n",
    "\n",
    "<sup> 1 </sup> **csv** (comma-separated values) là một định dạng file thông dụng để lưu trữ dữ liệu dạng bảng. Mỗi dòng trong file tương ứng với một hàng, dữ liệu trong một dòng mặc định được phân cách bằng dấu **phẩy**, hoặc các kí tự khác được tự định nghĩa (khoảng cách, tab, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnD_60TRqRf0"
   },
   "outputs": [],
   "source": [
    "# Có thể sử dụng thư viện hỗ trợ đọc file csv trong Python\n",
    "# Hoặc tiến hành đọc file như file text thông thường\n",
    "import csv\n",
    "\n",
    "with open('data/iris.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in list(reader)[::20]:\n",
    "        print(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RIj_hFZDqRf5"
   },
   "source": [
    "Để dễ dàng trong phân tích và xử lý các dữ liệu dạng bảng trên Python, một công cụ thường được sử dụng là **Pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgyS66KvqRf6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('data/iris.csv')\n",
    "\n",
    "# Lấy ra 5 mẫu ngẫu nhiên \n",
    "print(dataset.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWYaWVMWy_Ww"
   },
   "outputs": [],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_J2Ho5NzqXZ"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(dataset.iloc[:,0:5],hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X3C7_gOEqRf9"
   },
   "source": [
    "Một số kĩ thuật tiền xử lý dữ liệu có cấu trúc: \n",
    "\n",
    "- Xử lý dữ liệu bị mất (missing data)\n",
    "- Chuẩn hóa dữ liệu (normalization) \n",
    "- Rời rạc hóa dữ liệu (discretization)\n",
    "- Phát hiện và xử lý dữ liệu ngoại lai (outlier)\n",
    "\n",
    "Readmore: [Feature-Normalization](https://nbviewer.jupyter.org/github/thanhhff/AIVN-Machine-Learning/blob/master/Week%203/Feature-Normalization.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "evNE9InN03Cc"
   },
   "outputs": [],
   "source": [
    "### Rescaling Data: Max-min scaling - đưa các Future về đoạn [0;1] \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# Dữ liệu sepal_length \n",
    "original_data = dataset.iloc[:,0].values\n",
    "\n",
    "# dữ dữ liệu về đoạn [0;1]\n",
    "scaled_data = minmax_scale(original_data)\n",
    "\n",
    "# vẽ 2 đồ thị giữ liệu ban đầu và sau khi Scaling \n",
    "fig, ax=plt.subplots(1,2)\n",
    "sns.distplot(original_data, ax=ax[0], color='y')\n",
    "ax[0].set_title(\"Original Data\")\n",
    "sns.distplot(scaled_data, ax=ax[1])\n",
    "ax[1].set_title(\"Scaled data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXvTKt_pqRf-"
   },
   "source": [
    "## 2. Dữ liệu không có cấu trúc\n",
    "Các loại dữ liệu không có cấu trúc thường gặp:\n",
    "- Dữ liệu văn bản (text)\n",
    "- Dữ liệu hình ảnh (image)\n",
    "- Dữ liệu âm thanh (audio)\n",
    "- Dữ liệu chuỗi thời gian (time series)\n",
    "- etc.\n",
    "\n",
    "Đối với các dữ liệu không có cấu trúc, cần có các phương pháp khác nhau để chuyển đổi dữ liệu thô (raw data) thành dạng vector đặc trưng (feature vector) trước khi áp dụng các giải thuật Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AU_Otb443y8I"
   },
   "source": [
    "### 2.1 Dữ liệu hình ảnh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4tRCkZFXqRgw"
   },
   "source": [
    "#### a. Vector đặc trưng của ảnh\n",
    "- Hình ảnh được lưu trữ trong máy tính dưới dạng ma trận số, các số này thể hiện thông tin về màu sắc của các pixel trong ảnh. \n",
    "- Đối với định dạng ảnh RGB: kích thước ma trận gồm chiều dài, chiều rộng và chiều sâu, giá trị mỗi số trong ma trận nằm trong phạm vi [0-255] và thể hiện độ sáng của pixel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGVPHRlDqRgy"
   },
   "outputs": [],
   "source": [
    "# Ví dụ sử dụng thư viện Open-CV cho xử lý ảnh trong Python\n",
    "# https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html\n",
    "import cv2\n",
    "image = cv2.imread(\"img/cat.jpg\")\n",
    "\n",
    "print(\"shape =\", image.shape)\n",
    "print(image[:, :, 2])\n",
    "\n",
    "# Sử dụng thư viện Matplotlib để hiển thị ảnh trong Python\n",
    "# https://matplotlib.org/\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.subplots()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dopn9Y4QqRg0"
   },
   "outputs": [],
   "source": [
    "# CHÚ Ý: opencv đọc ảnh vào theo thứ tự BGR nên màu của ảnh bị \"ngược\" khi hiển thị ra\n",
    "# Chỉ cần đảo lại thứ tự của chiều channel để lấy lại thứ tự RGB nếu bạn muôn\n",
    "image = image[:, :, ::-1]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "alBVPo1LqRg3"
   },
   "source": [
    "#### b. Một số kỹ thuật tiền xử lý ảnh\n",
    "- Khi làm việc với dữ liệu ảnh trong Machine Learning/Deep Learning, kích thước của ảnh thường là cố định. Cần thay đổi kích thước ảnh đầu vào (resize hoặc crop ảnh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UGtd99Z5qRg4"
   },
   "outputs": [],
   "source": [
    "# Thay đổi kích thước ảnh\n",
    "resized_image = cv2.resize(image, (25, 25)) \n",
    "print(\"shape =\", resized_image.shape)\n",
    "print(resized_image[:, :, 2])\n",
    "\n",
    "plt.subplots()\n",
    "plt.imshow(resized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2b1LnKitqRg_"
   },
   "source": [
    "- Khi không quan tâm đến màu sắc của ảnh, có thể chuyển ảnh thành dạng ảnh xám (greyscale), lúc này, kích thước của ma trận chỉ gồm 2 giá trị là chiều dài và chiều rộng ảnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEsvtQbMqRg_"
   },
   "outputs": [],
   "source": [
    "# Chuyển sang ảnh xám\n",
    "greyscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "print (\"shape =\", greyscale_image.shape)\n",
    "print (greyscale_image[:, :])\n",
    "\n",
    "plt.subplots()\n",
    "plt.imshow(greyscale_image,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G09qX4ZyqRhB"
   },
   "source": [
    "- Để làm giàu cho tập dữ liệu (data augmentation), có thể sử dụng một số kỹ thuật như lật ảnh, xoay ảnh, hay dùng cách lớp mặt nạ (mask) để tạo ra các điểm dữ liệu mới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WFnHUW_5qRhC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Lật ảnh\n",
    "horizontal_img = cv2.flip(image, 0 )\n",
    "plt.subplot(141),plt.imshow(horizontal_img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "vertical_img = cv2.flip(image, 1 )\n",
    "plt.subplot(142),plt.imshow(vertical_img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "\n",
    "both_img = cv2.flip(image, -1 )\n",
    "plt.subplot(143),plt.imshow(both_img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# Xoay ảnh\n",
    "angle = 20\n",
    "image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "rot_img = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "plt.subplot(144),plt.imshow(rot_img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUWn1q3rqRhE"
   },
   "outputs": [],
   "source": [
    "# Với \"Mask\" là một ma trận cho trước \n",
    "# Sử dụng phép nhân hadamard để áp dụng lớp \"Mask\" lên hình ảnh\n",
    "\n",
    "mask = np.random.random(greyscale_image.shape[:2])\n",
    "masked_image = mask * greyscale_image\n",
    "\n",
    "plt.subplots()\n",
    "plt.imshow(masked_image,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n77eqk-n5YUc"
   },
   "source": [
    "### 2.2 Dữ liệu văn bản \n",
    "\n",
    "Mục đích của tiền xử lý dữ liệu văn bản là chuyển đổi các từ/kí tự trong văn bản thành các vector thể hiện đặc trưng của văn bản.\n",
    "\n",
    "Các phương pháp tiền xử lý văn bản thường gặp:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A_7Q07195uG6"
   },
   "source": [
    "#### a. Tokenization\n",
    "Là quá trình phân tách văn bản thành các từ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SnoWoBHs7Xbx"
   },
   "outputs": [],
   "source": [
    "sample_text = \"I am writing a sample text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQv9Ghav5teQ"
   },
   "outputs": [],
   "source": [
    "tokenized_text = sample_text.split()\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qSr_t-f5zcr"
   },
   "outputs": [],
   "source": [
    "# Sử dụng thư viện nltk để hỗ trợ xử lý dữ liệu text\n",
    "# https://www.nltk.org/\n",
    "\n",
    "import nltk\n",
    "\n",
    "\"\"\"\n",
    "Chú ý: Tải package phụ trợ nếu chưa có\n",
    "\"\"\"\n",
    "nltk.download('punkt')  \n",
    "\n",
    "tokenized_text = nltk.word_tokenize(sample_text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9B9EutwB7cxd"
   },
   "source": [
    "#### b. Loại bỏ Stopword: \n",
    "Stopword là các từ phổ biến trong ngôn ngữ và không mang ý nghĩa đặc trưng. Đối với các bài toán về phân loại văn bản, các stopword này sẽ được loại bỏ để giảm kích thước tập từ vựng (vocabulary) cũng như hạn chế nhiễu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c428vfTm7b8x"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\"\"\"\n",
    "Chú ý: Tải package phụ trợ nếu chưa có\n",
    "\"\"\"\n",
    "nltk.download('stopwords') \n",
    "\n",
    "english_stopword = stopwords.words('english')\n",
    "print(english_stopword[::5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hvwchdkz8GS8"
   },
   "source": [
    "#### c. Stemming\n",
    "Với một số ngôn ngữ như tiếng anh, từ vựng thường được biến đổi về hình thức do quy tắc về ngữ pháp. Đối với các bài toán chỉ quan tâm đến ngữ nghĩa của từ mà bỏ qua cấu trúc ngữ pháp, người ta thường dùng kỹ thuật stemming để đưa các từ về dạng gốc (cats -> cat, playing -> play)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFAd1A2b8F2O"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "stemmed_text = [ps.stem(word) for word in tokenized_text]\n",
    "print(stemmed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ArsxIcw9kXB"
   },
   "source": [
    "#### d. Xác định tập từ vựng (vocabulary)\n",
    "Đối với các bài toán về dữ liệu văn bản, cần xác định một tập từ vựng cố định, là các đặc trưng của văn bản. \n",
    "\n",
    "Tập từ vựng thường là tập hợp các từ xuất hiện trong tập dữ liệu huấn luyện, sau khi đã qua các bước như loại bỏ stopword, stemming, etc. Ngoài ra, để giới hạn kích thước tập từ vựng, ta cũng có thể loại bỏ các từ có tần xuất suất hiện quá thấp (các từ hiếm, nhiễu) hay quá phổ biến (các từ không mang nhiều ý nghĩa phân loại) trong toàn tập dữ liệu huấn luyện.\n",
    "\n",
    "Có thể sử dụng 1 phần từ **< UNK >** (Unknown word) để biểu diễn cho các từ không xuất hiện trong tập từ vựng.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xeqq6Haj9iIs"
   },
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    \"I am playing with text\",\n",
    "    \"It is a cat\",\n",
    "    \"I like cat\"\n",
    "]\n",
    "\n",
    "sample_texts = [nltk.word_tokenize(text) for text in sample_texts]\n",
    "vocab = set(sum(sample_texts, []))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cM6bXcVl-RCC"
   },
   "source": [
    "#### e. Chuyển văn bản về dạng vector đặc trưng (Word to Vectors)\n",
    "\n",
    "Nội dung phần này sẽ được giảng chi tiết trong \"Bài 11: Deep Learning trong lĩnh vực xử lý ngôn ngữ tự nhiên (NLP)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIACjdo9_q4i"
   },
   "outputs": [],
   "source": [
    "# CHÚ Ý: cần tạo index cho @UNKNOWN@ - từ/token không có trong từ điển\\\n",
    "vocab = set(sum(sample_texts, []))\n",
    "word2index = {'@UNKNOWN@': 0}\n",
    "index2word = {0: '@UNKNOWN@'}\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "\n",
    "    # word2index : key   - từ thuộc vocab \n",
    "    #               value - chỉ số của từ trong vocab\n",
    "    #               {'am': 0, 'I': 1, 'with': 2, ... } \n",
    "    # index2word : key   - chỉ số của từ trong vocab\n",
    "    #               value - từ thuộc vocab \n",
    "    #               {0: 'am', 1: 'I', 2: 'with', ... }\n",
    "    #\n",
    "    word2index[word] = i+1\n",
    "    index2word[i+1] = word\n",
    "    \n",
    "print(word2index)\n",
    "print(index2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWvZf7d1-01O"
   },
   "source": [
    "##### **Biểu diễn One-hot Vector**\n",
    "\n",
    "One-hot vector là vector có tất cả các giá trị bằng 0 và một giá trị duy nhất bằng 1. Vị trí có giá trị bằng 1 chính là giá trị integer mà vector đó biểu diễn. \n",
    "\n",
    "One-hot vector thường đường sử dụng để biểu diễn các biến kiểu phân loại (categorical variable) như các nhãn (label) của bài toán phân loại (classification). Trong các bài toán trên dữ liệu văn bản, One-hot vector cũng được sử đụng để biểu diễn các từ, thay cho giá trị index được biểu diễn ở trên.\n",
    "\n",
    "```Python\n",
    "        Ex: index_vector = [9, 7, 6, 2, 9, 7] \n",
    "        vocab = ['I', 'am', 'write', 'a', 'sampl', 'text', '.']\n",
    "        onehot_vectors = [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "                          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
    "                          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "                          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
    "                          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "                          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KLYmUqSdqRhG"
   },
   "source": [
    "## 3. Lưu trữ dữ liệu\n",
    "Trong quá trình huấn luyện mô hình, tiền xử lý dữ liệu là một bước làm tốn nhiều thời gian và bộ nhớ. Vì vậy thông thường, ta sẽ xử lý các dữ liệu thô (raw data), chuyển thành dạng vector đặc trưng và lưu trữ các vector này dưới dạng nhị phân để thuận tiện trong việc lưu trữ và sử dụng.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QAOLdOxLqRhT"
   },
   "source": [
    "#### Python Pickle\n",
    "- Cho phép lưu trữ các cấu trúc dữ liệu trong Python dưới dạng file nhị phân.\n",
    "- Các thao tác làm việc vói Pickle đơn giản và nhanh chóng\n",
    "\n",
    "- Lưu trữ file ở dạng Pickle gặp phải một số hạn chế về kích thước không gian lưu trữ tốc độ truy xuất dữ liệu khi làm việc với dữ liệu lớn \n",
    "\n",
    "READMORE: https://docs.python.org/3/library/pickle.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbeG4iZQqRhT"
   },
   "source": [
    "#### HDF5\n",
    "- Định dạng HDF5 được sử dụng để lưu trữ dữ liệu lớn dưới dạng file nhị phân\n",
    "- Dữ liệu được lưu trữ dưới dạng cấu trúc phân cấp (hierarchical structure)\n",
    "- Dễ dàng lưu trữ và làm việc với dữ liệu số, dữ liệu Numpy\n",
    "\n",
    "READMORE: http://docs.h5py.org/en/stable/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "AU_Otb443y8I",
    "4tRCkZFXqRgw",
    "alBVPo1LqRg3",
    "n77eqk-n5YUc",
    "A_7Q07195uG6",
    "9B9EutwB7cxd",
    "Hvwchdkz8GS8",
    "3ArsxIcw9kXB",
    "cM6bXcVl-RCC",
    "JWvZf7d1-01O",
    "KLYmUqSdqRhG",
    "QAOLdOxLqRhT",
    "FbeG4iZQqRhT"
   ],
   "name": "Tutorial 3 - Basic Data Manipulation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.3",
    "jupytext_version": "0.8.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
